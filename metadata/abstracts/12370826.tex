
Convolution kernels are essential tools in signal processing: they are used to filter noisy signal, interpolate discrete signals, \ldots. However, in a given application, it is often hard to select an optimal shape of the kernel. This is why, in practice, it may be useful to possess efficient tools to perform a robustness analysis, talking the form in our case of an imprecise convolution. When convolution kernels are positive, their formal equivalence with probability distributions allows one to use imprecise probability theory to achieve such an imprecise convolution. However, many kernels can have negative values, in which case the previous equivalence does not hold anymore. Yet, we show mathematically in this paper that, while the formal equivalence is lost, the computational tools used to describe sets of probabilities by intervals on the singletons still retain their key properties when used to approximate sets of (possibly) non-positive kernels. We then illustrate their use on a single application that consists of filtering a human electrocardiogram signal by using a low-pass filter whose order is imprecisely known. We show, in this experiment, that the proposed approach leads to tighter bounds than previously proposed approaches.
\keywords{Signal filtering \and Probability intervals \and Signed fuzzy measures \and Interval-valued filtering}

